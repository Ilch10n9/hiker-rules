[{
        "last_chapter_rule": "",
        "title": "ËΩªÂêàÈõÜ¬∑TyrantG",
        "author": "Â∞èÊ£âË¢Ñüåû&Ê∞∏Ëøú„ÅÆÊòéÊó•",
        "url": "hiker://empty",
        "version": 78,
        "col_type": "icon_2_round",
        "class_name": "",
        "type": "all",
        "class_url": "",
        "area_name": "",
        "area_url": "",
        "sort_name": "",
        "year_name": "",
        "sort_url": "",
        "year_url": "",
        "find_rule": "js:\nconst { dataLoad } = $.require('hiker://page/utility?rule=' + getItem('myCollection'))\nlet el = [{\n    title: ' ' + getItem('myCollection').bold() + ' &nbsp &nbsp ' + '‚öô ËΩªÂêàÈõÜËÆæÁΩÆ ‚öô'.small(),\n    url: 'hiker://page/Config?rule=' + getItem('myCollection'),\n    img: MY_RULE.icon || 'hiker://images/icon1',\n    col_type: 'avatar'\n}, {\n    url: '\"hiker://search?s=\"+input+\"&rule=' + getItem('myCollection') + '\"',\n    desc: 'Êêú‰Ω†ÊÉ≥Ë¶ÅÁöÑ...',\n    title: 'ÊêúÁ¥¢',\n    col_type: 'input'\n}]\n\nlet newWindow = readFile('newWindow')\ndataLoad().forEach((v) => {\n    let fypage = /^[^;]*?fypage.*?(;.*)?$/.test(v.url) ? 'fypage' : '1',\n        d = {\n            title: v.title,\n            url: 'hiker://page/indexLoad?#' + fypage + '#noHistory#',\n            img: v.icon,\n            extra: { RULE: v }\n        }\n    if(newWindow) Object.assign(d.extra, { newWindow: true, windowId: getItem('myCollection') + d.title })\n    el.push(d)\n})\nsetResult(el)",
        "search_url": "hiker://empty?keyword=**&page=fypage",
        "group": "‚ë†ËΩªÂêàÈõÜ",
        "searchFind": "js:\nvar { dataLoad, runCode, urlParse } = $.require('hiker://page/utility?rule=' + getItem('myCollection'))\nlet myCollection_el = [],\n    searchThd = parseInt(readFile('searchThd') || '5'),\n    keyword = getParam('keyword'),\n    pageNum = parseInt(getParam('page')),\n    RULES = dataLoad().filter((v) => v.search_url)\nif (searchThd == 0) {\n    myCollection_el.push({\n        title: ('‚¨á ÈÄâÊã©‰∏Ä‰∏™Â∞èÁ®ãÂ∫èÊü•Áúã' + keyword + 'ÁöÑÊêúÁ¥¢ÁªìÊûú ‚¨á').small(),\n        url: 'hiker://empty'\n    })\n    RULES.forEach((v) => myCollection_el.push({\n        title: v.title,\n        url: \"hiker://page/singleSearch?keyword=\" + keyword + \"&page=fypage\",\n        extra: { rule: getItem('myCollection'), RULE: v },\n    }))\n} else if (searchThd > 0) {\n    let searchCount = pageNum * searchThd,\n        searchTag = { title: '‚¨Ü Â∑≤ÊêúÁ¥¢‰∫Ü' + searchCount + '‰∏™Â∞èÁ®ãÂ∫è ‚¨Ü\\n‚¨á ‰∏ãÈù¢ËøòÊúâ' + RULES.slice(searchCount).length + '‰∏™Â∞èÁ®ãÂ∫è ‚¨á' }\n    RULES = RULES.slice(searchCount - searchThd, searchCount)\n    if (!RULES.length) setResult([])\n\n    let URLS = RULES.map((RULE) => {\n        MY_RULE.ua = RULE.ua\n        let urlReq = urlParse(RULE.search_url, {}, 1, (url) => {\n            url[0] = url[0].replace(url[0].includes('%%') ? /%%/g : /\\*\\*/g, encodeStr(keyword, url[2]))\n        })\n        return { url: urlReq.MY_URL, options: urlReq.MY_URL_Options }\n    })\n    batchFetch(URLS).forEach((indexHtml, index) => {\n        // Â§ÑÁêÜMY_URLÂíåMY_RULE\n        let RULE = RULES[index]\n        MY_URL = URLS[index].url\n        MY_RULE.ua = RULE.ua\n        MY_RULE.col_type = RULE.col_type\n        MY_RULE.detail_col_type = ['', '*'].includes(RULE.sdetail_find_rule) ? RULE.detail_col_type : RULE.sdetail_col_type\n        MY_RULE.find_rule = RULE.searchFind\n        MY_RULE.detail_find_rule = ['', '*'].includes(RULE.sdetail_find_rule) ? RULE.detail_find_rule : RULE.sdetail_find_rule\n        MY_RULE.preRule = RULE.preRule\n        MY_RULE.pageList = JSON.parse(RULE.pages || '[]')\n        MY_RULE.pages = JSON.stringify(MY_RULE.pageList)\n        MY_RULE.last_chapter_rule = RULE.last_chapter_rule\n        MY_RULE.params = {}\n        MY_RULE.url = MY_URL\n        MY_RULE.urlHeaders = URLS[index].options.headers\n\n        // Ê≠£ÊñáËß£Êûê\n        eval(MY_RULE.preRule)\n        if (MY_RULE.find_rule.startsWith('js:')) {\n            function getUrl() {\n                return MY_URL\n            }\n\n            function getResCode() {\n                return indexHtml\n            }\n\n            setResult = function(el) {\n                if (Array.isArray(el.data)) el = el.data\n                Array.prototype.push.apply(myCollection_el, el.map((v) => {\n                    let MY__RULE = Object.assign({}, MY_RULE, { title: RULE.title })\n                    v.desc = RULE.title + ' ‚ñ™ ' + (v.desc || '')\n\n                    if (!v.url || ['rule', 'pics', 'toast', 'input', 'copy', 'editFile', 'x5', 'x5WebView', 'x5Play', 'web', 'select', 'x5Rule', 'webRule'].find((vv) => v.url.startsWith(vv + '://'))) {\n                        return v\n                    } else if (v.url.includes('@rule=')) {\n                        let [_, url, rule] = v.url.match(/^([\\s\\S]*?)@rule=([\\s\\S]*)$/)\n                        v.url = url\n                        MY__RULE.detail_find_rule = rule\n                        MY__RULE.detail_col_type = MY_RULE.col_type\n                    } else if (v.url.startsWith('hiker://page/')) {\n                        if (v.url.includes('rule=') || (v.extra || {}).rule)\n                            return v\n                        let [_, path, params] = v.url.split('#')[0].match(/^hiker:\\/\\/page\\/(.+?)(?:\\?(.*))?$/),\n                            subPage = MY_RULE.pageList.find((v) => v.path == path),\n                            subUrl = (params || '').split('&').find((v) => v.startsWith('url='))\n                        v.url = subUrl ? subUrl.slice(4).replace(/ÔºüÔºü/g, '?').replace(/ÔºÜÔºÜ/g, '&') : (v.extra || {}).url || 'hiker://empty?' + (params || '')\n                        MY__RULE.detail_find_rule = subPage.rule\n                        MY__RULE.detail_col_type = subPage.col_type\n                        MY__RULE.params = v.extra || {}\n                    } else if (v.url.includes('@lazyRule=')) {\n                        v.url = v.url.replace('.js:', '.js:\\nif(MY_RULE)Object.assign(MY_RULE,' + $.stringify({ pages: MY_RULE.pages, pageList: MY_RULE.pageList, find_rule: '', params: '' }) + ');MY_URL=\"' + MY_URL + '\";')\n                        return v\n                    } else if (!MY_RULE.detail_find_rule || v.url.startsWith('hiker://')) { return v }\n                    v.extra = { url: v.url, RULE: MY__RULE, pageTitle: v.title }\n                    v.url = 'hiker://page/detailLoad?rule=' + getItem('myCollection')\n                    if (v.extra.RULE.url.includes('#immersiveTheme#')) v.url += '&#immersiveTheme#'\n\n                    return v\n                }))\n            }\n            setHomeResult = setResult\n            setSearchResult = setResult\n\n            try {\n                eval(MY_RULE.find_rule.slice(3))\n            } catch (e) {}\n        } else {\n            let findRule = MY_RULE.find_rule.split(';')\n            parseDomForArray(indexHtml, findRule.shift()).forEach((data) => {\n                let [title, url, desc, content, img] = findRule.map((v, i) => {\n                        try {\n                            if (v == '*') return ''\n                            else v = (i == 1 || i == 4) ?\n                                parseDom(data, v) :\n                                parseDomForHtml(data, v)\n                            if (i != 1) v = runCode(v)\n                            return v\n                        } catch (e) { return '' }\n                    }),\n                    res = {\n                        title: title,\n                        url: url,\n                        desc: RULE.title + ' ‚ñ™ ' + desc,\n                        content: content,\n                        img: img\n                    }\n                if (res.url) {\n                    let MY__RULE = Object.assign({}, MY_RULE, { title: RULE.title })\n                    if (res.url.includes('@lazyRule=')) {\n                        res.url = res.url.replace('.js:', '.js:\\nif(MY_RULE)Object.assign(MY_RULE,' + $.stringify({ pages: MY__RULE.pages, pageList: MY__RULE.pageList, find_rule: '', params: '' }) + ');MY_URL=\"' + MY_URL + '\";')\n                    } else if (MY_RULE.detail_find_rule) {\n                        res.extra = { url: url, RULE: MY__RULE, pageTitle: title }\n                        res.url = 'hiker://page/detailLoad?rule=' + getItem('myCollection')\n                        if (res.extra.RULE.url.includes('#immersiveTheme#')) res.url += '&#immersiveTheme#'\n                    }\n                }\n                myCollection_el.push(res)\n            })\n        }\n    })\n    myCollection_el.push(searchTag)\n}\nmethod_setResult.invoke(javaContext, myCollection_el, CALLBACK_KEY, MY_RULE, MY_TYPE)\n",
        "detail_col_type": "movie_1",
        "detail_find_rule": "",
        "sdetail_col_type": "movie_1",
        "sdetail_find_rule": "",
        "ua": "mobile",
        "preRule": "setItem('myCollection', MY_RULE.title)\nsetItem('remoteUrl', 'https://git.tyrantg.com/tyrantgenesis/hikerViewRules/raw/master/data/rules.json')\n// \n// ÂåÖË£πÈîôËØØ",
        "pages": "[{\"col_type\":\"text_1\",\"name\":\"ClassTab\",\"path\":\"ClassTab\",\"rule\":\"function ClassTab(classArray, params) {\\n    Object.assign(this, params)\\n    this.arr = classArray.map(v => this.init(v))\\n    this.sign = '$' + MY_RULE.title + '_' + (this.name || '') + '_'\\n    this.color = this.color || '#12b668'\\n    this.boundary = this.boundary || 'blank_block'\\n}\\nClassTab.prototype = {\\n    constructor: ClassTab,\\n    load(el) {\\n        let folded = getVar('fold_' + this.sign, '')\\n        if (this.fold) el.push({\\n            title: '‚Äú‚Äú‚Äù‚Äù<span style=\\\"color:#049eff\\\">' + (folded ? '‚ñ∂' : '‚ñº'),\\n            url: $('#noLoading#').lazyRule((sign, folded) => {\\n                putVar('fold_' + sign, { '': 'T', 'T': '' } [folded])\\n                refreshPage(false)\\n                return 'hiker://empty'\\n            }, this.sign, folded),\\n            col_type: 'scroll_button'\\n        })\\n        let arr = folded ? [this.arr[0]] : this.arr\\n        arr.forEach((v) => {\\n            let { id, class_name, class_url } = v,\\n                selected = JSON.stringify(this.getClass(id))\\n            class_name.forEach((name, i) => {\\n                let url = class_url[i],\\n                    now = JSON.stringify({ name: name, url: url })\\n                el.push({\\n                    title: (selected == now ? '‚Äú‚Äú‚Äù‚Äù<span style=\\\"color:' + this.color + '\\\"><b>' : '') + name,\\n                    url: $('#noLoading#').lazyRule((sign, id, now) => {\\n                        putVar(sign + id, now)\\n                        putVar(sign, now)\\n                        refreshPage(false)\\n                        return 'hiker://empty'\\n                    }, this.sign, id, now),\\n                    col_type: 'scroll_button'\\n                })\\n            })\\n            el.push({ col_type: this.boundary })\\n        })\\n    },\\n    init(classObject) {\\n        if (typeof classObject.class_name == 'string')\\n            classObject.class_name = classObject.class_name.split('&')\\n        if (typeof classObject.class_url == 'string')\\n            classObject.class_url = classObject.class_url.split('&').map((v) => v.trim())\\n        return classObject\\n    },\\n    push(classObject) {\\n        this.arr.push(this.init(classObject))\\n    },\\n    getClass(id) {\\n        let defaultClass = this.arr.find(item => item.id == id)\\n        if (defaultClass) defaultClass = JSON.stringify({\\n            name: defaultClass.class_name[0],\\n            url: defaultClass.class_url[0]\\n        })\\n        else throw new Error('cannot find id: ' + id + ' in classTab: ' + this.sign)\\n        return JSON.parse(getVar(this.sign + id, defaultClass))\\n    },\\n    getLastClick() {\\n        return JSON.parse(getVar(this.sign, '{}'))\\n    },\\n    setUrl(url) {\\n        return url.replace(/\\\\$\\\\{([^}]*)\\\\}/g, (_, id) => this.getClass(id).url)\\n    }\\n}\\n$.exports = ClassTab\\n\"},{\"col_type\":\"movie_3\",\"name\":\"È¶ñÈ°µ\",\"path\":\"indexLoad\",\"rule\":\"js:\\nlet myCollection_el = [],\\n    pageNum = parseInt(MY_URL.split('#')[1]),\\n    RULE = MY_PARAMS.RULE,\\n    fyAll = RULE.url.includes('fyAll'),\\n    // Âä†ËΩΩClassTabÁªÑ‰ª∂\\n    ClassTab = $.require('hiker://page/ClassTab?rule=' + getItem('myCollection')),\\n    tabHeader = []\\n\\nif (RULE.class_name) tabHeader.push({\\n    id: fyAll ? 'fyAll' : 'fyclass',\\n    class_name: RULE.class_name,\\n    class_url: RULE.class_url\\n})\\nif (RULE.area_name) tabHeader.push({\\n    id: fyAll ? 'fyAll' : 'fyarea',\\n    class_name: RULE.area_name,\\n    class_url: RULE.area_url\\n})\\nif (RULE.year_name) tabHeader.push({\\n    id: fyAll ? 'fyAll' : 'fyyear',\\n    class_name: RULE.year_name,\\n    class_url: RULE.year_url\\n})\\nif (RULE.sort_name) tabHeader.push({\\n    id: fyAll ? 'fyAll' : 'fysort',\\n    class_name: RULE.sort_name,\\n    class_url: RULE.sort_url\\n})\\ntabHeader = new ClassTab(tabHeader, { name: RULE.title })\\nif (pageNum == 1) {\\n    addListener('onClose', 'clearVar(\\\"myCollection-searchMode\\\")')\\n    putVar('myCollection-searchMode', RULE.title)\\n    tabHeader.load(myCollection_el)\\n    if (RULE.search_url) myCollection_el.push({\\n        title: \\\"ÊêúÁ¥¢\\\",\\n        desc: \\\"Êêú‰Ω†ÊÉ≥Ë¶ÅÁöÑ...\\\",\\n        url: '\\\"hiker://page/singleSearch?keyword=\\\"+input+\\\"&page=fypage\\\"',\\n        extra: { rule: getItem('myCollection'), RULE: RULE },\\n        col_type: \\\"input\\\",\\n    })\\n}\\n// Â§ÑÁêÜMY_URLÂíåMY_RULE\\nMY_RULE.ua = RULE.ua\\nMY_RULE.title = RULE.title\\nMY_RULE.col_type = RULE.col_type\\nMY_RULE.detail_col_type = RULE.detail_col_type\\nMY_RULE.find_rule = RULE.find_rule\\nMY_RULE.detail_find_rule = RULE.detail_find_rule\\nMY_RULE.preRule = RULE.preRule\\nMY_RULE.pageList = JSON.parse(RULE.pages || '[]')\\nMY_RULE.pages = JSON.stringify(MY_RULE.pageList)\\nMY_RULE.last_chapter_rule = RULE.last_chapter_rule\\nMY_RULE.params = {}\\n\\nconst { runCode, urlParse } = $.require('hiker://page/utility?rule=' + getItem('myCollection'))\\nvar { MY_URL, MY_URL_Options } = urlParse(RULE.url, {}, pageNum, (url) => {\\n    url[0] = fyAll ? url[0].replace(/fyAll/g, '$${fyAll}') : url[0].replace(/fy(class|area|year|sort)/g, '$${fy$1}')\\n    url[0] = tabHeader.setUrl(url[0])\\n}),\\n    indexHtml = fetch(MY_URL, MY_URL_Options)\\nMY_RULE.url = MY_URL\\nMY_RULE.urlHeaders = MY_URL_Options.headers\\n// Ê≠£ÊñáËß£Êûê\\nif (pageNum == 1) eval(MY_RULE.preRule)\\nif (MY_RULE.find_rule.startsWith('js:')) {\\n    function getUrl() {\\n        return MY_URL\\n    }\\n\\n    function getResCode() {\\n        return indexHtml\\n    }\\n\\n    function setResult(el, param1, param2, param3) {\\n        param1 = CALLBACK_KEY\\n        param2 = MY_RULE\\n        param3 = MY_TYPE\\n        if (Array.isArray(el.data)) el = el.data\\n        Array.prototype.push.apply(myCollection_el, el.map((v) => {\\n            let MY__RULE = Object.assign({}, MY_RULE)\\n            v.col_type = v.col_type || MY_RULE.col_type\\n\\n            if (!v.url || ['rule', 'pics', 'toast', 'input', 'copy', 'editFile', 'x5', 'x5WebView', 'x5Play', 'web', 'select', 'x5Rule', 'webRule'].find((vv) => v.url.startsWith(vv + '://'))) {\\n                return v\\n            } else if (v.url.includes('@rule=')) {\\n                let [_, url, rule] = v.url.match(/^([\\\\s\\\\S]*?)@rule=([\\\\s\\\\S]*)$/)\\n                v.url = url\\n                MY__RULE.detail_find_rule = rule\\n                MY__RULE.detail_col_type = MY_RULE.col_type\\n            } else if (v.url.startsWith('hiker://page/')) {\\n                if (v.url.includes('rule=') || (v.extra || {}).rule)\\n                    return v\\n                let [_, path, params] = v.url.split('#')[0].match(/^hiker:\\\\/\\\\/page\\\\/(.+?)(?:\\\\?(.*))?$/),\\n                    subPage = MY_RULE.pageList.find((v) => v.path == path),\\n                    subUrl = (params || '').split('&').find((v) => v.startsWith('url='))\\n                v.url = subUrl ? subUrl.slice(4).replace(/ÔºüÔºü/g, '?').replace(/ÔºÜÔºÜ/g, '&') : (v.extra || {}).url || 'hiker://empty?' + (params || '')\\n                MY__RULE.detail_find_rule = subPage.rule\\n                MY__RULE.detail_col_type = subPage.col_type\\n                MY__RULE.params = v.extra || {}\\n            } else if (v.url.includes('@lazyRule=')) {\\n                v.url = v.url.replace('.js:', '.js:\\\\nif(MY_RULE)Object.assign(MY_RULE,' + $.stringify({ pages: MY_RULE.pages, pageList: MY_RULE.pageList, find_rule: '', params: '' }) + ');MY_URL=\\\"' + MY_URL + '\\\";')\\n                return v\\n            } else if (!MY_RULE.detail_find_rule || v.url.startsWith('hiker://')) { return v }\\n            v.extra = { url: v.url, RULE: MY__RULE, pageTitle: v.title }\\n            v.url = 'hiker://page/detailLoad?rule=' + getItem('myCollection')\\n            if (v.extra.RULE.url.includes('#immersiveTheme#')) v.url += '&#immersiveTheme#'\\n            return v\\n        }))\\n        method_setResult.invoke(javaContext, myCollection_el, param1, param2, param3)\\n    }\\n    setHomeResult = setResult\\n    setSearchResult = setResult\\n\\n    eval(MY_RULE.find_rule.slice(3))\\n} else {\\n    let findRule = MY_RULE.find_rule.split(';')\\n    parseDomForArray(indexHtml, findRule.shift()).forEach((data) => {\\n        let [title, img, desc, url] = findRule.map((v, i) => {\\n                try {\\n                    if (v == '*') return ''\\n                    else v = (i == 1 || i == 3) ?\\n                        parseDom(data, v) :\\n                        parseDomForHtml(data, v)\\n                    if (i != 3) v = runCode(v)\\n                    return v\\n                } catch (e) { return '' }\\n            }),\\n            res = {\\n                title: title,\\n                url: url,\\n                desc: desc,\\n                img: img,\\n                col_type: MY_RULE.col_type\\n            }\\n        if (res.url) {\\n            if (res.url.includes('@lazyRule=')) {\\n                res.url = res.url.replace('.js:', '.js:\\\\nif(MY_RULE)Object.assign(MY_RULE,' + $.stringify({ pages: MY_RULE.pages, pageList: MY_RULE.pageList, find_rule: '', params: '' }) + ');MY_URL=\\\"' + MY_URL + '\\\";')\\n            } else if (MY_RULE.detail_find_rule) {\\n                res.extra = { url: url, RULE: MY_RULE, pageTitle: title }\\n                res.url = 'hiker://page/detailLoad?rule=' + getItem('myCollection')\\n                if (res.extra.RULE.url.includes('#immersiveTheme#')) res.url += '&#immersiveTheme#'\\n            }\\n        }\\n        myCollection_el.push(res)\\n    })\\n    setResult(myCollection_el)\\n}\\n\"},{\"col_type\":\"movie_3\",\"name\":\"ËØ¶ÊÉÖ\",\"path\":\"detailLoad\",\"rule\":\"js:\\nlet myCollection_el = [],\\n    pageNum = 1\\n\\n// Â§ÑÁêÜMY_URLÂíåMY_RULE\\nlet RULE = MY_PARAMS.RULE\\nMY_RULE.ua = RULE.ua\\nMY_RULE.title = RULE.title\\nMY_RULE.col_type = RULE.detail_col_type\\nMY_RULE.find_rule = RULE.detail_find_rule\\nMY_RULE.preRule = RULE.preRule\\nMY_RULE.pageList = RULE.pageList\\nMY_RULE.pages = RULE.pages\\nMY_RULE.last_chapter_rule = RULE.last_chapter_rule\\nMY_RULE.params = RULE.params\\n\\nconst { runCode, urlParse } = $.require('hiker://page/utility?rule=' + getItem('myCollection'))\\nlet fypageFlag = MY_PARAMS.url.indexOf('fypage')\\nif (fypageFlag >= 0) pageNum = parseInt(/^\\\\d+/.exec(MY_URL.slice(fypageFlag)))\\nvar { MY_URL, MY_URL_Options } = urlParse(MY_PARAMS.url, RULE.urlHeaders, pageNum),\\n    indexHtml = fetch(MY_URL, MY_URL_Options)\\nMY_RULE.url = MY_URL\\nMY_RULE.urlHeaders = MY_URL_Options.headers\\n// Ëß£ÊûêÊ≠£Êñá\\nif (MY_PARAMS.pageTitle) setPageTitle(MY_PARAMS.pageTitle)\\neval(MY_RULE.preRule)\\nsetLastChapterRule(MY_RULE.last_chapter_rule)\\nMY_PARAMS = MY_RULE.params\\nif (MY_RULE.find_rule.startsWith('js:')) {\\n    function getUrl() {\\n        return MY_URL\\n    }\\n\\n    function getResCode() {\\n        return indexHtml\\n    }\\n\\n    function setResult(el, param1, param2, param3) {\\n        param1 = CALLBACK_KEY\\n        param2 = MY_RULE\\n        param3 = MY_TYPE\\n        if (Array.isArray(el.data)) el = el.data\\n        Array.prototype.push.apply(myCollection_el, el.map((v) => {\\n            let MY__RULE = Object.assign({}, MY_RULE)\\n            v.col_type = v.col_type || MY_RULE.col_type\\n\\n            if (!v.url || ['rule', 'pics', 'toast', 'input', 'copy', 'editFile', 'x5', 'x5WebView', 'x5Play', 'web', 'select', 'x5Rule', 'webRule'].find((vv) => v.url.startsWith(vv + '://'))) {\\n                return v\\n            } else if (v.url.includes('@rule=')) {\\n                let [_, url, rule] = v.url.match(/^([\\\\s\\\\S]*?)@rule=([\\\\s\\\\S]*)$/)\\n                v.url = url\\n                MY__RULE.detail_find_rule = rule\\n                MY__RULE.detail_col_type = MY_RULE.col_type\\n            } else if (v.url.startsWith('hiker://page/')) {\\n                if (v.url.includes('rule=') || (v.extra || {}).rule)\\n                    return v\\n                let [_, path, params] = v.url.split('#')[0].match(/^hiker:\\\\/\\\\/page\\\\/(.+?)(?:\\\\?(.*))?$/),\\n                    subPage = MY_RULE.pageList.find((v) => v.path == path),\\n                    subUrl = (params || '').split('&').find((v) => v.startsWith('url='))\\n                v.url = subUrl ? subUrl.slice(4).replace(/ÔºüÔºü/g, '?').replace(/ÔºÜÔºÜ/g, '&') : (v.extra || {}).url || 'hiker://empty?' + (params || '')\\n                MY__RULE.detail_find_rule = subPage.rule\\n                MY__RULE.detail_col_type = subPage.col_type\\n                MY__RULE.params = v.extra || {}\\n            } else if (v.url.includes('@lazyRule=')) {\\n                v.url = v.url.replace('.js:', '.js:\\\\nif(MY_RULE)Object.assign(MY_RULE,' + $.stringify({ pages: MY_RULE.pages, pageList: MY_RULE.pageList, find_rule: '', params: '' }) + ');MY_URL=\\\"' + MY_URL + '\\\";')\\n                return v\\n            } else { return v }\\n            v.extra = { url: v.url, RULE: MY__RULE }\\n            v.url = 'hiker://page/detailLoad?rule=' + getItem('myCollection')\\n            if (v.extra.RULE.url.includes('#immersiveTheme#')) v.url += '&#immersiveTheme#'\\n            return v\\n        }))\\n        method_setResult.invoke(javaContext, myCollection_el, param1, param2, param3)\\n    }\\n    setHomeResult = setResult\\n    setSearchResult = setResult\\n\\n    eval(MY_RULE.find_rule.slice(3))\\n} else {\\n    let [_, findRule, detailFindRule] = MY_RULE.find_rule.match(/^(.*?)(?:==>(.*))?$/)\\n    findRule = findRule.split(';')\\n    parseDomForArray(indexHtml, findRule.shift()).forEach((data) => {\\n        let [title, img, desc, url] = findRule.map((v, i) => {\\n                try {\\n                    if (v == '*') return ''\\n                    else v = (i == 1 || i == 3) ?\\n                        parseDom(data, v) :\\n                        parseDomForHtml(data, v)\\n                    if (i != 3) v = runCode(v)\\n                    return v\\n                } catch (e) { return '' }\\n            }),\\n            res = {\\n                title: title,\\n                url: url,\\n                desc: desc,\\n                img: img,\\n                col_type: MY_RULE.col_type\\n            }\\n        if (res.url) {\\n            if (res.url.includes('@lazyRule=')) {\\n                res.url = res.url.replace('.js:', '.js:\\\\nif(MY_RULE)Object.assign(MY_RULE,' + $.stringify({ pages: MY_RULE.pages, pageList: MY_RULE.pageList, find_rule: '', params: '' }) + ');MY_URL=\\\"' + MY_URL + '\\\";')\\n            } else if (detailFindRule) {\\n                res.extra = { url: url, RULE: Object.assign({}, MY_RULE, { detail_find_rule: detailFindRule }) }\\n                res.url = 'hiker://page/detailLoad?rule=' + getItem('myCollection')\\n                if (res.extra.RULE.url.includes('#immersiveTheme#')) res.url += '&#immersiveTheme#'\\n            }\\n        }\\n        myCollection_el.push(res)\\n    })\\n    setResult(myCollection_el)\\n}\\n\"},{\"col_type\":\"movie_3\",\"name\":\"Â∑•ÂÖ∑ÈõÜ\",\"path\":\"utility\",\"rule\":\"$.exports = {\\n    dataLoad: function(showAll) {\\n        //Ê£ÄÊü•Èó¥ÈöîÔºåÈªòËÆ§‰∏ÄÂ§©\\n        let interval = parseInt(readFile('updateInterval') || '1'),\\n            time = parseInt(readFile('updateTime')) || 0,\\n            now = new Date().getTime(),\\n            data = []\\n        if (time == 0 || interval > 0 && now - time > 1000 * 60 * 60 * 24 * interval) {\\n            // Ëé∑ÂèñËøúÁ®ãÊï∞ÊçÆ\\n            let url = getItem('remoteUrl')\\n            try {\\n                let remoteData = fetch(url)\\n                if (url.startsWith('hiker://page/'))\\n                    remoteData = JSON.parse(remoteData).rule\\n                data = JSON.parse(remoteData)\\n            } catch (e) {}\\n            if(data.length == 0) {\\n                data = JSON.parse(readFile('dataCache') || '[]')\\n                log('Ê≤°ÊúâËé∑ÂèñÂà∞Êõ¥Êñ∞Êï∞ÊçÆ')\\n            } else {\\n                data = data.filter((v) => { return v.title != getItem('myCollection') && !v.author.includes('ËΩªÂêàÈõÜÁîüÊàêÂô®') })\\n                saveFile('dataCache', JSON.stringify(data))\\n                saveFile('updateTime', now.toString())\\n                log('Êõ¥Êñ∞Êï∞ÊçÆÂ∑≤ÂÜôÂÖ•Êú¨Âú∞')\\n            }\\n        } else {\\n            data = JSON.parse(readFile('dataCache') || '[]')\\n        }\\n        // ÂÜôÂÖ•Ëá™ÂÆö‰πâÊï∞ÊçÆ\\n        let customData = JSON.parse(readFile('customData') || '[]'),\\n            rewriteData = []\\n        customData = customData.reduce((self, v) => {\\n            let index = data.findIndex((vv) => v.title == vv.title)\\n            if (index >= 0) {\\n                self.push(v)\\n                let rule = data.splice(index, 1)[0]\\n                if(showAll || v.visible)\\n                    rewriteData.push(Object.assign(rule, v))\\n            }\\n            return self\\n        }, [])\\n        data.forEach((v) => customData.push({ title: v.title, visible: true }))\\n        saveFile('customData', JSON.stringify(customData))\\n        return rewriteData.concat(data)\\n    },\\n    runCode: function(rule) {\\n        try {\\n            let [input, code] = rule.split('.js:')\\n            return code ? eval(code) : rule\\n        } catch (e) { return rule }\\n    },\\n    urlParse: function(url, headers, pageNum, func) {\\n        url = url.split(';').map((v) => v.replace(/ÔºõÔºõ/g, ';'))\\n        if (func) func(url)\\n        url[0] = url[0].replace(/fypage(?:@(-?\\\\d+)@)?(?:\\\\*(\\\\d+)@)?/, (_, start, space) => parseInt(start || 0) + 1 + (pageNum - 1) * parseInt(space || 1))\\n        url[0] = /^([\\\\s\\\\S]*?)(?:\\\\[firstPage=([\\\\s\\\\S]*?)\\\\])?$/.exec(url[0])\\n        url[0] = runCode(url[0][2] && pageNum == 1 ? url[0][2] : url[0][1])\\n        let options = { headers: headers, method: url[1] }\\n        // postÊñπÊ≥ïÊó∂ËΩ¨Êç¢ÂèÇÊï∞\\n        if (/^post$/i.test(options['method'])) {\\n            let [oriUrl, body] = url[0].split('?')\\n            url[0] = oriUrl.replace(/ÔºüÔºü/g, '?')\\n            if (body.startsWith('JsonBody=')) body = body.slice(9)\\n            options['body'] = body\\n        }\\n        if (url[2]) options.headers['Content-Type'] = 'text/plain;charst=' + url[2]\\n        if (url[3]) url[3].match(/{(.*)}/)[1].split('&&').forEach((v) => {\\n            let [key, value] = v.split('@')\\n            options.headers[key] = runCode(value)\\n        })\\n        // Ê∑ªÂä†ÂÖ®Â±ÄUA\\n        if (!options.headers['User-Agent']) {\\n            if (MY_RULE.ua == 'pc')\\n                options.headers['User-Agent'] = PC_UA\\n            else if (MY_RULE.ua == 'mobile')\\n                options.headers['User-Agent'] = MOBILE_UA\\n        }\\n        return { MY_URL: url[0], MY_URL_Options: options }\\n    }\\n}\\n\"},{\"col_type\":\"movie_1_vertical_pic\",\"name\":\"ÂçïÊêú\",\"path\":\"singleSearch\",\"rule\":\"js:\\nlet myCollection_el = [],\\n    RULE = MY_PARAMS.RULE,\\n    keyword = getParam('keyword'),\\n    pageNum = parseInt(getParam('page'))\\n\\n// Â§ÑÁêÜMY_URLÂíåMY_RULE\\nMY_TYPE = 'search'\\nMY_RULE.ua = RULE.ua\\nMY_RULE.title = RULE.title\\nMY_RULE.col_type = RULE.col_type\\nMY_RULE.detail_col_type = ['', '*'].includes(RULE.sdetail_find_rule) ? RULE.detail_col_type : RULE.sdetail_col_type\\nMY_RULE.find_rule = RULE.searchFind\\nMY_RULE.detail_find_rule = ['', '*'].includes(RULE.sdetail_find_rule) ? RULE.detail_find_rule : RULE.sdetail_find_rule\\nMY_RULE.preRule = RULE.preRule\\nMY_RULE.pageList = JSON.parse(RULE.pages || '[]')\\nMY_RULE.pages = JSON.stringify(MY_RULE.pageList)\\nMY_RULE.last_chapter_rule = RULE.last_chapter_rule\\nMY_RULE.params = {}\\n\\nconst { runCode, urlParse } = $.require('hiker://page/utility?rule=' + getItem('myCollection'))\\nvar { MY_URL, MY_URL_Options } = urlParse(RULE.search_url, {}, pageNum, (url) => {\\n    url[0] = url[0].replace(url[0].includes('%%') ? /%%/g : /\\\\*\\\\*/g, encodeStr(keyword, url[2]))\\n}),\\n    indexHtml = fetch(MY_URL, MY_URL_Options)\\nMY_RULE.url = MY_URL\\nMY_RULE.urlHeaders = MY_URL_Options.headers\\n// Ê≠£ÊñáËß£Êûê\\nif (pageNum == 1) setPageTitle('‚Äú' + keyword + '‚ÄùÁöÑÊêúÁ¥¢ÁªìÊûú')\\nif (MY_RULE.find_rule.startsWith('js:')) {\\n    function getUrl() {\\n        return MY_URL\\n    }\\n\\n    function getResCode() {\\n        return indexHtml\\n    }\\n\\n    function setResult(el, param1, param2, param3) {\\n        param1 = CALLBACK_KEY\\n        param2 = MY_RULE\\n        param3 = MY_TYPE\\n        if (Array.isArray(el.data)) el = el.data\\n        Array.prototype.push.apply(myCollection_el, el.map((v) => {\\n            let MY__RULE = Object.assign({}, MY_RULE),\\n                subTitle = v.title\\n            v.title += '‚Äú‚Äú‚Äù‚Äù<br>' + (RULE.title.fontcolor('#12b668') + ' ‚ñ™ ' + (v.desc || '').fontcolor('#666666')).small()\\n            v.desc = v.content || ''\\n            if(!v.img && !v.pic_url) v.col_type = 'text_1'\\n            delete v.content\\n\\n            if (!v.url || ['rule', 'pics', 'toast', 'input', 'copy', 'editFile', 'x5', 'x5WebView', 'x5Play', 'web', 'select', 'x5Rule', 'webRule'].find((vv) => v.url.startsWith(vv + '://'))) {\\n                return v\\n            } else if (v.url.includes('@rule=')) {\\n                let [_, url, rule] = v.url.match(/^([\\\\s\\\\S]*?)@rule=([\\\\s\\\\S]*)$/)\\n                v.url = url\\n                MY__RULE.detail_find_rule = rule\\n                MY__RULE.detail_col_type = MY_RULE.col_type\\n            } else if (v.url.startsWith('hiker://page/')) {\\n                if (v.url.includes('rule=') || (v.extra || {}).rule)\\n                    return v\\n                let [_, path, params] = v.url.split('#')[0].match(/^hiker:\\\\/\\\\/page\\\\/(.+?)(?:\\\\?(.*))?$/),\\n                    subPage = MY_RULE.pageList.find((v) => v.path == path),\\n                    subUrl = (params || '').split('&').find((v) => v.startsWith('url='))\\n                v.url = subUrl ? subUrl.slice(4).replace(/ÔºüÔºü/g, '?').replace(/ÔºÜÔºÜ/g, '&') : (v.extra || {}).url || 'hiker://empty?' + (params || '')\\n                MY__RULE.detail_find_rule = subPage.rule\\n                MY__RULE.detail_col_type = subPage.col_type\\n                MY__RULE.params = v.extra || {}\\n            } else if (v.url.includes('@lazyRule=')) {\\n                v.url = v.url.replace('.js:', '.js:\\\\nif(MY_RULE)Object.assign(MY_RULE,' + $.stringify({ pages: MY_RULE.pages, pageList: MY_RULE.pageList, find_rule: '', params: '' }) + ');MY_URL=\\\"' + MY_URL + '\\\";')\\n                return v\\n            } else if (!MY_RULE.detail_find_rule || v.url.startsWith('hiker://')) { return v }\\n            v.extra = { url: v.url, RULE: MY__RULE, pageTitle: subTitle }\\n            v.url = 'hiker://page/detailLoad?rule=' + getItem('myCollection')\\n            if (v.extra.RULE.url.includes('#immersiveTheme#')) v.url += '&#immersiveTheme#'\\n            return v\\n        }))\\n        method_setResult.invoke(javaContext, myCollection_el, param1, param2, param3)\\n    }\\n    setHomeResult = setResult\\n    setSearchResult = setResult\\n\\n    eval(MY_RULE.find_rule.slice(3))\\n} else {\\n    let findRule = MY_RULE.find_rule.split(';')\\n    parseDomForArray(indexHtml, findRule.shift()).forEach((data) => {\\n        let [title, url, desc, content, img] = findRule.map((v, i) => {\\n                try {\\n                    if (v == '*') return ''\\n                    else v = (i == 1 || i == 4) ?\\n                        parseDom(data, v) :\\n                        parseDomForHtml(data, v)\\n                    if (i != 1) v = runCode(v)\\n                    return v\\n                } catch (e) { return '' }\\n            }),\\n            res = {\\n                title: title + '‚Äú‚Äú‚Äù‚Äù<br>' + (RULE.title.fontcolor('#12b668') + ' ‚ñ™ ' + desc.fontcolor('#666666')).small(),\\n                url: url,\\n                desc: content,\\n                img: img\\n            }\\n        if(!res.img) res.col_type = 'text_1'\\n        if (res.url) {\\n            if (res.url.includes('@lazyRule=')) {\\n                res.url = res.url.replace('.js:', '.js:\\\\nif(MY_RULE)Object.assign(MY_RULE,' + $.stringify({ pages: MY_RULE.pages, pageList: MY_RULE.pageList, find_rule: '', params: '' }) + ');MY_URL=\\\"' + MY_URL + '\\\";')\\n            } else if (MY_RULE.detail_find_rule) {\\n                res.extra = { url: url, RULE: MY_RULE, pageTitle: title }\\n                res.url = 'hiker://page/detailLoad?rule=' + getItem('myCollection')\\n                if (res.extra.RULE.url.includes('#immersiveTheme#')) res.url += '&#immersiveTheme#'\\n            }\\n        }\\n        myCollection_el.push(res)\\n    })\\n    setResult(myCollection_el)\\n}\\n\"},{\"col_type\":\"icon_2_round\",\"name\":\"ËÆæÁΩÆ\",\"path\":\"Config\",\"rule\":\"js:\\naddListener('onClose', 'clearVar(\\\"myCollection-sortFlag\\\");refreshPage()')\\nsetPageTitle('‚öô ËΩªÂêàÈõÜËÆæÁΩÆ ‚öô')\\nconst { dataLoad } = $.require('hiker://page/utility?rule=' + getItem('myCollection'))\\nlet data = dataLoad(true),\\n    el = [{\\n        title: 'Ê∏ÖÈô§ÁºìÂ≠ò,Á´ãÂç≥Êõ¥Êñ∞ <small> ÔºàÂü∫‰∫éËøúÁ®ã‰ªìÂ∫ì,‰∏çË¶ÅÈ¢ëÁπÅÁÇπÂáªÔºâ',\\n        url: $().lazyRule(() => {\\n            deleteFile('updateTime')\\n            back(false)\\n            return 'toast://Â∑≤Êõ¥Êñ∞'\\n        }),\\n        img: 'hiker://images/icon1',\\n        col_type: 'avatar'\\n    }],\\n    searchThd = readFile('searchThd') || '5',\\n    updateInterval = readFile('updateInterval') || '1',\\n    newWindow = readFile('newWindow'),\\n    editMode = getVar('myCollection-editMode', 'ÂêØÁî®/Á¶ÅÁî®')\\n\\nel.push({\\n    title: '  üîç ÊêúÁ¥¢Ê®°Âºè: ' + (searchThd == 0 ? 'Âàó' : 'ËÅö' + searchThd) + '  ',\\n    url: $(['ÂàóË°®ÊêúÁ¥¢', 'ËÅöÂêàÊêúÁ¥¢'], 1).select((searchThd) => {\\n        if (input == 'ÂàóË°®ÊêúÁ¥¢') {\\n            saveFile('searchThd', '0')\\n            refreshPage()\\n        } else {\\n            if (searchThd == 0) searchThd = 5\\n            return $(searchThd, 'ËæìÂÖ•ÊêúÁ¥¢Á∫øÁ®ãÔºåÊúÄÂ•Ω‰∏çË¶ÅË∂ÖËøá16').input(() => {\\n                saveFile('searchThd', input)\\n                refreshPage()\\n            })\\n        }\\n    }, searchThd),\\n    col_type: 'scroll_button'\\n}, {\\n    title: '  üí° Êõ¥Êñ∞È¢ëÁéá: ' + (updateInterval < 1 ? 'ÊâãÂä®' : updateInterval + 'Â§©') + '  ',\\n    url: $(updateInterval, 'ËæìÂÖ•Êõ¥Êñ∞Èó¥ÈöîÔºàÂ§©ÔºâÔºå‰∏∫0ÂàôÊâãÂä®Êõ¥Êñ∞').input(() => {\\n        saveFile('updateInterval', input)\\n        refreshPage()\\n        return 'hiker://empty'\\n    }),\\n    col_type: 'scroll_button'\\n}, {\\n    title: '  üñ• Áã¨Á´ãÈ¶ñÈ°µ: ' + (newWindow ? 'ÊòØ' : 'Âê¶') + '  ',\\n    url: $('#noLoading#').lazyRule((newWindow) => {\\n        saveFile('newWindow', newWindow ? '' : '1')\\n        refreshPage()\\n        return 'hiker://empty'\\n    }, newWindow),\\n    col_type: 'scroll_button'\\n}, {\\n    title: '‚Äú‚Äú‚Äù‚Äù<font color=\\\"#666666\\\"><small>ÁâπÂà´È∏£Ë∞¢ÔºåÂ∞èÁ®ãÂ∫èÊèê‰æõËÄÖÔºö\\\\n' +\\n        data.reduce((self, v) => v.author ? self.concat(v.author.split('&')) : self, [])\\n        .filter((v, i, arr) => v && arr.indexOf(v) == i).join('„ÄÅ'),\\n    url: 'hiker://empty',\\n    col_type: 'text_center_1'\\n})\\n\\nel.push({ col_type: 'line' }, { col_type: 'big_blank_block' });\\n['ÂêØÁî®/Á¶ÅÁî®', 'ÈáçÊñ∞ÊéíÂ∫è', 'Êõ¥ÊîπÂõæÊ†á', 'ÂØºÂÖ•Êµ∑Èòî'].forEach((v) => {\\n    el.push({\\n        title: v == editMode ? '‚Äú‚Äú‚Äù‚Äù' + v.bold().fontcolor('#12b668') : v,\\n        url: v == editMode ? 'hiker://empty' : $('#noLoading#').lazyRule((v) => {\\n            putVar('myCollection-editMode', v)\\n            refreshPage(false)\\n            return 'hiker://empty'\\n        }, v),\\n        col_type: 'scroll_button'\\n    })\\n})\\nel.push({\\n    title: 'ÊÅ¢Â§çÂá∫ÂéÇÊï∞ÊçÆ',\\n    url: $('Á°ÆÂÆöË¶ÅÊÅ¢Â§çÂá∫ÂéÇÔºåÊ∏ÖÊ•öËá™ÂÆö‰πâÊï∞ÊçÆÂêóÔºü').confirm(() => {\\n        deleteFile('customData')\\n        refreshPage(false)\\n        return 'toast://Â∑≤ÊÅ¢Â§çÂá∫ÂéÇÊï∞ÊçÆ'\\n    }),\\n    col_type: 'scroll_button'\\n})\\n\\nJSON.parse(readFile('customData') || '[]').forEach((v, i) => {\\n    let d = { title: v.title, img: data[i].icon }\\n    switch (editMode) {\\n        case 'ÂêØÁî®/Á¶ÅÁî®':\\n            d.title = (v.visible ? 'üü¢  ' : 'üî¥  ') + d.title\\n            d.url = $('#noLoading#').lazyRule((rule) => {\\n                let rules = JSON.parse(readFile('customData') || '[]'),\\n                    index = rules.findIndex((v) => v.title == rule.title)\\n                rules[index].visible = !rules[index].visible\\n                saveFile('customData', JSON.stringify(rules))\\n                refreshPage(false)\\n                return 'hiker://empty'\\n            }, v)\\n            break\\n        case 'ÈáçÊñ∞ÊéíÂ∫è':\\n            let sortFlag = parseInt(getVar('myCollection-sortFlag', '-1'))\\n            d.title = (sortFlag == i ? 'üîÉ  ' : '') + d.title\\n            if (sortFlag == -1)\\n                d.url = $('#noLoading#').lazyRule((i) => {\\n                    putVar('myCollection-sortFlag', i.toString())\\n                    refreshPage(false)\\n                    return 'toast://ÈÄâÊã©Ë¶ÅÁßªÂä®Âà∞ÁöÑ‰ΩçÁΩÆ'\\n                }, i)\\n            else\\n                d.url = $('#noLoading#').lazyRule((oldIndex, newIndex) => {\\n                    let rules = JSON.parse(readFile('customData') || '[]')\\n                    rules.splice(newIndex, 0, rules.splice(oldIndex, 1)[0])\\n                    saveFile('customData', JSON.stringify(rules))\\n                    putVar('myCollection-sortFlag', '-1')\\n                    refreshPage(false)\\n                    return 'hiker://empty'\\n                }, sortFlag, i)\\n            break\\n        case 'Êõ¥ÊîπÂõæÊ†á':\\n            d.url = $(v.icon || '', 'ËæìÂÖ•Êñ∞ÂõæÊ†áÂú∞ÂùÄÊàñÈ¢úËâ≤‰ª£Á†ÅÔºö').input((rule) => {\\n                let rules = JSON.parse(readFile('customData') || '[]'),\\n                    index = rules.findIndex((v) => v.title == rule.title)\\n                if (input)\\n                    rules[index].icon = input\\n                else\\n                    delete rules[index].icon\\n                saveFile('customData', JSON.stringify(rules))\\n                refreshPage(false)\\n                return 'hiker://empty'\\n            }, v)\\n            break\\n        case 'ÂØºÂÖ•Êµ∑Èòî':\\n            d.url = 'rule://' + base64Encode(JSON.stringify(data[i]))\\n            break\\n    }\\n    el.push(d)\\n})\\nsetResult(el)\\n\"}]",
        "icon": "https://git.tyrantg.com/tyrantgenesis/hikerViewRules/raw/master/assets/images/avatar.jpg"
    },
    {
        "last_chapter_rule": "",
        "title": "ËΩªÁõ¥Êí≠.Tee",
        "author": "Â∞èÊ£âË¢Ñüåû",
        "url": "hiker://empty##https://shuyuan.miaogongzi.net/shuyuan/1640882974.txt",
        "version": 20211230,
        "col_type": "text_3",
        "class_name": "",
        "type": "live",
        "class_url": "",
        "area_name": "",
        "area_url": "",
        "sort_name": "",
        "year_name": "",
        "sort_url": "",
        "year_url": "",
        "find_rule": "js:\nvar data = [];\ndata.push({\n    title: \"üîé\",\n    url: \"'hiker://search?rule=\" + MY_RULE.title + \"&s='+input\",\n    desc: \"ÊêúÁ¥¢È¢ëÈÅì\",\n    col_type: \"input\"\n})\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1])\nsetResult(data);",
        "search_url": "hiker://empty##**",
        "group": "‚ë•Áõ¥Êí≠",
        "searchFind": "js:\nlet rule = JSON.parse(fetch(\"hiker://home@\" + MY_RULE.title))\nlet key = MY_URL.split(\"##\")[1];\nMY_URL = rule.url;\nvar data = [];\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1], key)\nsetResult(data);",
        "detail_col_type": "movie_1",
        "detail_find_rule": "",
        "sdetail_col_type": "movie_1",
        "sdetail_find_rule": "",
        "ua": "mobile",
        "preRule": "",
        "pages": "[{\"col_type\":\"movie_3\",\"name\":\"Â∑•ÂÖ∑\",\"path\":\"tool\",\"rule\":\"function getReferer(url) {\\n    if (url.indexOf(\\\"gitee\\\") > 0) {\\n        return \\\"https://\\\" + url.split(\\\"://\\\")[1].split(\\\"/\\\")[0];\\n    } else {\\n        return null\\n    }\\n}\\n\\nfunction renderLiveData(url, filter) {\\n    try {\\n        let _d = [];\\n        try {\\n            let net = request(url, {\\n                headers: {\\n                    Referer: getReferer(url)\\n                }\\n            });\\n            if (net.includes(\\\"<html>\\\")) {\\n                throw \\\"not xxx\\\";\\n            }\\n            var txts = net.replace(/#EXTINF:-1 ,/g, '')\\n                .replace(/#EXTINF:-1,/g, '')\\n                .replace(/\\\\n#genre#/g, ',#genre#')\\n                .replace(/#EXTINF:-1/g, '')\\n                .replace(/group-title=\\\"/g, '')\\n                .replace(/\\\\nhttp/g, ',http')\\n                .replace(/=/g, '')\\n                .replace(/Ôºå#/g, ',#')\\n                .replace(/\\\",/g, '/')\\n                .replace(/ /g, '')\\n                .split('\\\\n');\\n            const d1 = []\\n            for (var i = 0; i < txts.length; i++) {\\n                var r = {};\\n                var j = txts[i].split(',');\\n                if (txts[i].indexOf(\\\"#EXTINF\\\") == 0 &&\\n                    j.length == 3 && j[2].indexOf(\\\"http\\\") == 0) {\\n                    r.title = j[1].split('/')[j[0].split('/').length - 1];\\n                    r.url = j[2].replace(`\\\\n`, '').replace('\\\\r', '');\\n                    if (r.url.indexOf(\\\"http\\\") == 0) {\\n                        r.url = r.url + \\\"#isVideo=true#\\\";\\n                    }\\n                    d1.push(r);\\n                    continue;\\n                }\\n\\n                if (j.length < 2) {\\n                    continue;\\n                }\\n                r.title = j[0].split('/')[j[0].split('/').length - 1];\\n                if (filter != null && !r.title.includes(filter)) {\\n                    continue;\\n                }\\n                r.url = j[1].replace(`\\\\n`, '').replace('\\\\r', '');\\n                if (r.url.indexOf(\\\"http\\\") == 0) {\\n                    r.url = r.url + \\\"#isVideo=true#\\\";\\n                }\\n                d1.push(r);\\n            }\\n            //Â§öÁ∫øË∑Ø\\n            const d2 = {}\\n            for (let it of d1) {\\n                if (d2[it.title] == null) {\\n                    d2[it.title] = []\\n                }\\n                d2[it.title].push(it.url)\\n            }\\n\\n            for (let it of Object.keys(d2)) {\\n                _d.push({\\n                    title: it,\\n                    url: JSON.stringify({\\n                        urls: d2[it]\\n                    })\\n                })\\n            }\\n        } catch (e) {}\\n        if (_d && _d.length) {\\n            data = data.concat(_d)\\n            saveFile(\\\"data.json\\\", JSON.stringify(_d));\\n        } else {\\n            let _td = readFile(\\\"data.json\\\");\\n            if (_td) {\\n                data = data.concat(JSON.parse(_td))\\n            }\\n        }\\n    } catch (e) {\\n        data.push({\\n            title: \\\"Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•\\\",\\n            desc: JSON.stringify(e),\\n            col_type: \\\"text_1\\\"\\n        })\\n    }\\n}\\n$.exports = {\\n    renderLiveData: renderLiveData,\\n}\"}]",
        "icon": ""
    },
    {
        "last_chapter_rule": "",
        "title": "ËΩªÁõ¥Êí≠.‰∏ÉÂΩ©",
        "author": "Â∞èÊ£âË¢Ñüåû",
        "url": "hiker://empty##http://82.156.222.77/iptv/tv.txt",
        "version": 35,
        "col_type": "text_3",
        "class_name": "",
        "type": "live",
        "class_url": "",
        "area_name": "",
        "area_url": "",
        "sort_name": "",
        "year_name": "",
        "sort_url": "",
        "year_url": "",
        "find_rule": "js:\nvar data = [];\ndata.push({\n    title: \"üîé\",\n    url: \"'hiker://search?rule=\" + MY_RULE.title + \"&s='+input\",\n    desc: \"ÊêúÁ¥¢È¢ëÈÅì\",\n    col_type: \"input\"\n})\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1])\nsetResult(data);",
        "search_url": "hiker://empty##**",
        "group": "‚ë•Áõ¥Êí≠",
        "searchFind": "js:\nlet rule = JSON.parse(fetch(\"hiker://home@\" + MY_RULE.title))\nlet key = MY_URL.split(\"##\")[1];\nMY_URL = rule.url;\nvar data = [];\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1], key)\nsetResult(data);",
        "detail_col_type": "movie_1",
        "detail_find_rule": "",
        "sdetail_col_type": "movie_1",
        "sdetail_find_rule": "",
        "ua": "mobile",
        "preRule": "",
        "pages": "[{\"col_type\":\"movie_3\",\"name\":\"Â∑•ÂÖ∑\",\"path\":\"tool\",\"rule\":\"function getReferer(url) {\\n    if (url.indexOf(\\\"gitee\\\") > 0) {\\n        return \\\"https://\\\" + url.split(\\\"://\\\")[1].split(\\\"/\\\")[0];\\n    } else {\\n        return null\\n    }\\n}\\n\\nfunction renderLiveData(url, filter) {\\n    try {\\n        let _d = [];\\n        try {\\n            let net = request(url, {\\n                headers: {\\n                    Referer: getReferer(url)\\n                }\\n            });\\n            if (net.includes(\\\"<html>\\\")) {\\n                throw \\\"not xxx\\\";\\n            }\\n            var txts = net.replace(/#EXTINF:-1 ,/g, '')\\n                .replace(/#EXTINF:-1,/g, '')\\n                .replace(/\\\\n#genre#/g, ',#genre#')\\n                .replace(/#EXTINF:-1/g, '')\\n                .replace(/group-title=\\\"/g, '')\\n                .replace(/\\\\nhttp/g, ',http')\\n                //.replace(/=/g, '')\\n                .replace(/Ôºå#/g, ',#')\\n                .replace(/\\\",/g, '/')\\n                .replace(/ /g, '')\\n                .split('\\\\n');\\n            const d1 = []\\n            for (var i = 0; i < txts.length; i++) {\\n                var r = {};\\n                var j = txts[i].split(',');\\n                if (txts[i].indexOf(\\\"#EXTINF\\\") == 0 &&\\n                    j.length == 3 && j[2].indexOf(\\\"http\\\") == 0) {\\n                    r.title = j[1].split('/')[j[0].split('/').length - 1];\\n                    r.url = j[2].replace(`\\\\n`, '').replace('\\\\r', '');\\n                    if (r.url.indexOf(\\\"http\\\") == 0 || r.url.indexOf(\\\"rtmp\\\") == 0 || r.url.indexOf(\\\"rtsp\\\") == 0) {\\n                        r.url = r.url + \\\"#isVideo=true#\\\";\\n                    }\\n                    d1.push(r);\\n                    continue;\\n                }\\n\\n                if (j.length < 2) {\\n                    continue;\\n                }\\n                r.title = j[0].split('/')[j[0].split('/').length - 1];\\n                if (filter != null && !r.title.includes(filter)) {\\n                    continue;\\n                }\\n                r.url = j[1].replace(`\\\\n`, '').replace('\\\\r', '');\\n                if (r.url.indexOf(\\\"http\\\") == 0 || r.url.indexOf(\\\"rtmp\\\") == 0 || r.url.indexOf(\\\"rtsp\\\") == 0) {\\n                    r.url = r.url + \\\"#isVideo=true#\\\";\\n                }\\n                d1.push(r);\\n            }\\n            //Â§öÁ∫øË∑Ø\\n            const d2 = {}\\n            for (let it of d1) {\\n                if (d2[it.title] == null) {\\n                    d2[it.title] = []\\n                }\\n                d2[it.title].push(it.url)\\n            }\\n\\n            for (let it of Object.keys(d2)) {\\n                _d.push({\\n                    title: it,\\n                    url: JSON.stringify({\\n                        urls: d2[it]\\n                    })\\n                })\\n            }\\n        } catch (e) {}\\n        if (_d && _d.length) {\\n            data = data.concat(_d)\\n            saveFile(\\\"data.json\\\", JSON.stringify(_d));\\n        } else {\\n            let _td = readFile(\\\"data.json\\\");\\n            if (_td) {\\n                data = data.concat(JSON.parse(_td))\\n            }\\n        }\\n    } catch (e) {\\n        data.push({\\n            title: \\\"Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•\\\",\\n            desc: JSON.stringify(e),\\n            col_type: \\\"text_1\\\"\\n        })\\n    }\\n}\\n$.exports = {\\n    renderLiveData: renderLiveData,\\n}\"}]",
        "icon": ""
    },
    {
        "last_chapter_rule": "",
        "title": "ËΩªÁõ¥Êí≠.ËôéÁâôÁîµÂΩ±",
        "author": "Â∞èÊ£âË¢Ñüåû",
        "url": "hiker://empty##https://shuyuan.miaogongzi.net/shuyuan/1639655798.txt",
        "version": 35,
        "col_type": "text_3",
        "class_name": "",
        "type": "live",
        "class_url": "",
        "area_name": "",
        "area_url": "",
        "sort_name": "",
        "year_name": "",
        "sort_url": "",
        "year_url": "",
        "find_rule": "js:\nvar data = [];\ndata.push({\n    title: \"üîé\",\n    url: \"'hiker://search?rule=\" + MY_RULE.title + \"&s='+input\",\n    desc: \"ÊêúÁ¥¢È¢ëÈÅì\",\n    col_type: \"input\"\n})\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1])\nsetResult(data);",
        "search_url": "hiker://empty##**",
        "group": "‚ë•Áõ¥Êí≠",
        "searchFind": "js:\nlet rule = JSON.parse(fetch(\"hiker://home@\" + MY_RULE.title))\nlet key = MY_URL.split(\"##\")[1];\nMY_URL = rule.url;\nvar data = [];\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1], key)\nsetResult(data);",
        "detail_col_type": "movie_1",
        "detail_find_rule": "",
        "sdetail_col_type": "movie_1",
        "sdetail_find_rule": "",
        "ua": "mobile",
        "preRule": "",
        "pages": "[{\"col_type\":\"movie_3\",\"name\":\"Â∑•ÂÖ∑\",\"path\":\"tool\",\"rule\":\"function getReferer(url) {\\n    if (url.indexOf(\\\"gitee\\\") > 0) {\\n        return \\\"https://\\\" + url.split(\\\"://\\\")[1].split(\\\"/\\\")[0];\\n    } else {\\n        return null\\n    }\\n}\\n\\nfunction renderLiveData(url, filter) {\\n    try {\\n        let _d = [];\\n        try {\\n            let net = request(url, {\\n                headers: {\\n                    Referer: getReferer(url)\\n                }\\n            });\\n            if (net.includes(\\\"<html>\\\")) {\\n                throw \\\"not xxx\\\";\\n            }\\n            var txts = net.replace(/#EXTINF:-1 ,/g, '')\\n                .replace(/#EXTINF:-1,/g, '')\\n                .replace(/\\\\n#genre#/g, ',#genre#')\\n                .replace(/#EXTINF:-1/g, '')\\n                .replace(/group-title=\\\"/g, '')\\n                .replace(/\\\\nhttp/g, ',http')\\n                //.replace(/=/g, '')\\n                .replace(/Ôºå#/g, ',#')\\n                .replace(/\\\",/g, '/')\\n                .replace(/ /g, '')\\n                .split('\\\\n');\\n            const d1 = []\\n            for (var i = 0; i < txts.length; i++) {\\n                var r = {};\\n                var j = txts[i].split(',');\\n                if (txts[i].indexOf(\\\"#EXTINF\\\") == 0 &&\\n                    j.length == 3 && j[2].indexOf(\\\"http\\\") == 0) {\\n                    r.title = j[1].split('/')[j[0].split('/').length - 1];\\n                    r.url = j[2].replace(`\\\\n`, '').replace('\\\\r', '');\\n                    if (r.url.indexOf(\\\"http\\\") == 0 || r.url.indexOf(\\\"rtmp\\\") == 0 || r.url.indexOf(\\\"rtsp\\\") == 0) {\\n                        r.url = r.url + \\\"#isVideo=true#\\\";\\n                    }\\n                    d1.push(r);\\n                    continue;\\n                }\\n\\n                if (j.length < 2) {\\n                    continue;\\n                }\\n                r.title = j[0].split('/')[j[0].split('/').length - 1];\\n                if (filter != null && !r.title.includes(filter)) {\\n                    continue;\\n                }\\n                r.url = j[1].replace(`\\\\n`, '').replace('\\\\r', '');\\n                if (r.url.indexOf(\\\"http\\\") == 0 || r.url.indexOf(\\\"rtmp\\\") == 0 || r.url.indexOf(\\\"rtsp\\\") == 0) {\\n                    r.url = r.url + \\\"#isVideo=true#\\\";\\n                }\\n                d1.push(r);\\n            }\\n            //Â§öÁ∫øË∑Ø\\n            const d2 = {}\\n            for (let it of d1) {\\n                if (d2[it.title] == null) {\\n                    d2[it.title] = []\\n                }\\n                d2[it.title].push(it.url)\\n            }\\n\\n            for (let it of Object.keys(d2)) {\\n                _d.push({\\n                    title: it,\\n                    url: JSON.stringify({\\n                        urls: d2[it]\\n                    })\\n                })\\n            }\\n        } catch (e) {}\\n        if (_d && _d.length) {\\n            data = data.concat(_d)\\n            saveFile(\\\"data.json\\\", JSON.stringify(_d));\\n        } else {\\n            let _td = readFile(\\\"data.json\\\");\\n            if (_td) {\\n                data = data.concat(JSON.parse(_td))\\n            }\\n        }\\n    } catch (e) {\\n        data.push({\\n            title: \\\"Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•\\\",\\n            desc: JSON.stringify(e),\\n            col_type: \\\"text_1\\\"\\n        })\\n    }\\n}\\n$.exports = {\\n    renderLiveData: renderLiveData,\\n}\"}]",
        "icon": ""
    },
    {
        "last_chapter_rule": "",
        "title": "ËΩªÁõ¥Êí≠.È¨ºÊâç",
        "author": "Â∞èÊ£âË¢Ñüåû",
        "url": "hiker://empty##https://gitee.com/lzhgc/diy/raw/1/%E8%8A%82%E7%9B%AE",
        "version": 35,
        "col_type": "text_3",
        "class_name": "",
        "type": "live",
        "class_url": "",
        "area_name": "",
        "area_url": "",
        "sort_name": "",
        "year_name": "",
        "sort_url": "",
        "year_url": "",
        "find_rule": "js:\nvar data = [];\ndata.push({\n    title: \"üîé\",\n    url: \"'hiker://search?rule=\" + MY_RULE.title + \"&s='+input\",\n    desc: \"ÊêúÁ¥¢È¢ëÈÅì\",\n    col_type: \"input\"\n})\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1])\nsetResult(data);",
        "search_url": "hiker://empty##**",
        "group": "‚ë•Áõ¥Êí≠",
        "searchFind": "js:\nlet rule = JSON.parse(fetch(\"hiker://home@\" + MY_RULE.title))\nlet key = MY_URL.split(\"##\")[1];\nMY_URL = rule.url;\nvar data = [];\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1], key)\nsetResult(data);",
        "detail_col_type": "movie_1",
        "detail_find_rule": "",
        "sdetail_col_type": "movie_1",
        "sdetail_find_rule": "",
        "ua": "mobile",
        "preRule": "",
        "pages": "[{\"col_type\":\"movie_3\",\"name\":\"Â∑•ÂÖ∑\",\"path\":\"tool\",\"rule\":\"function getReferer(url) {\\n    if (url.indexOf(\\\"gitee\\\") > 0) {\\n        return \\\"https://\\\" + url.split(\\\"://\\\")[1].split(\\\"/\\\")[0];\\n    } else {\\n        return null\\n    }\\n}\\n\\nfunction renderLiveData(url, filter) {\\n    try {\\n        let _d = [];\\n        try {\\n            let net = request(url, {\\n                headers: {\\n                    Referer: getReferer(url)\\n                }\\n            });\\n            if (net.includes(\\\"<html>\\\")) {\\n                throw \\\"not xxx\\\";\\n            }\\n            var txts = net.replace(/#EXTINF:-1 ,/g, '')\\n                .replace(/#EXTINF:-1,/g, '')\\n                .replace(/\\\\n#genre#/g, ',#genre#')\\n                .replace(/#EXTINF:-1/g, '')\\n                .replace(/group-title=\\\"/g, '')\\n                .replace(/\\\\nhttp/g, ',http')\\n                //.replace(/=/g, '')\\n                .replace(/Ôºå#/g, ',#')\\n                .replace(/\\\",/g, '/')\\n                .replace(/ /g, '')\\n                .split('\\\\n');\\n            const d1 = []\\n            for (var i = 0; i < txts.length; i++) {\\n                var r = {};\\n                var j = txts[i].split(',');\\n                if (txts[i].indexOf(\\\"#EXTINF\\\") == 0 &&\\n                    j.length == 3 && j[2].indexOf(\\\"http\\\") == 0) {\\n                    r.title = j[1].split('/')[j[0].split('/').length - 1];\\n                    r.url = j[2].replace(`\\\\n`, '').replace('\\\\r', '');\\n                    if (r.url.indexOf(\\\"http\\\") == 0 || r.url.indexOf(\\\"rtmp\\\") == 0 || r.url.indexOf(\\\"rtsp\\\") == 0) {\\n                        r.url = r.url + \\\"#isVideo=true#\\\";\\n                    }\\n                    d1.push(r);\\n                    continue;\\n                }\\n\\n                if (j.length < 2) {\\n                    continue;\\n                }\\n                r.title = j[0].split('/')[j[0].split('/').length - 1];\\n                if (filter != null && !r.title.includes(filter)) {\\n                    continue;\\n                }\\n                r.url = j[1].replace(`\\\\n`, '').replace('\\\\r', '');\\n                if (r.url.indexOf(\\\"http\\\") == 0 || r.url.indexOf(\\\"rtmp\\\") == 0 || r.url.indexOf(\\\"rtsp\\\") == 0) {\\n                    r.url = r.url + \\\"#isVideo=true#\\\";\\n                }\\n                d1.push(r);\\n            }\\n            //Â§öÁ∫øË∑Ø\\n            const d2 = {}\\n            for (let it of d1) {\\n                if (d2[it.title] == null) {\\n                    d2[it.title] = []\\n                }\\n                d2[it.title].push(it.url)\\n            }\\n\\n            for (let it of Object.keys(d2)) {\\n                _d.push({\\n                    title: it,\\n                    url: JSON.stringify({\\n                        urls: d2[it]\\n                    })\\n                })\\n            }\\n        } catch (e) {}\\n        if (_d && _d.length) {\\n            data = data.concat(_d)\\n            saveFile(\\\"data.json\\\", JSON.stringify(_d));\\n        } else {\\n            let _td = readFile(\\\"data.json\\\");\\n            if (_td) {\\n                data = data.concat(JSON.parse(_td))\\n            }\\n        }\\n    } catch (e) {\\n        data.push({\\n            title: \\\"Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•\\\",\\n            desc: JSON.stringify(e),\\n            col_type: \\\"text_1\\\"\\n        })\\n    }\\n}\\n$.exports = {\\n    renderLiveData: renderLiveData,\\n}\"}]",
        "icon": ""
    },
    {
        "last_chapter_rule": "",
        "title": "ËΩªÁõ¥Êí≠.‰∏çÁü•Âêç",
        "author": "Â∞èÊ£âË¢Ñüåû",
        "url": "hiker://empty##https://pastebin.com/raw/AHJEEkB4",
        "version": 37,
        "col_type": "text_3",
        "class_name": "",
        "type": "live",
        "class_url": "",
        "area_name": "",
        "area_url": "",
        "sort_name": "",
        "year_name": "",
        "sort_url": "",
        "year_url": "",
        "find_rule": "js:\nvar data = [];\ndata.push({\n    title: \"üîé\",\n    url: \"'hiker://search?rule=\" + MY_RULE.title + \"&s='+input\",\n    desc: \"ÊêúÁ¥¢È¢ëÈÅì\",\n    col_type: \"input\"\n})\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1])\nsetResult(data);",
        "search_url": "hiker://empty##**",
        "group": "‚ë•Áõ¥Êí≠",
        "searchFind": "js:\nlet rule = JSON.parse(fetch(\"hiker://home@\" + MY_RULE.title))\nlet key = MY_URL.split(\"##\")[1];\nMY_URL = rule.url;\nvar data = [];\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1], key)\nsetResult(data);",
        "detail_col_type": "movie_1",
        "detail_find_rule": "",
        "sdetail_col_type": "movie_1",
        "sdetail_find_rule": "",
        "ua": "mobile",
        "preRule": "",
        "pages": "[{\"col_type\":\"movie_3\",\"name\":\"Â∑•ÂÖ∑\",\"path\":\"tool\",\"rule\":\"function getReferer(url) {\\n    if (url.indexOf(\\\"gitee\\\") > 0) {\\n        return \\\"https://\\\" + url.split(\\\"://\\\")[1].split(\\\"/\\\")[0];\\n    } else {\\n        return null\\n    }\\n}\\n\\nfunction renderLiveData(url, filter) {\\n    try {\\n        let _d = [];\\n        try {\\n            let net = request(url, {\\n                headers: {\\n                    Referer: getReferer(url)\\n                }\\n            });\\n            if (net.includes(\\\"<html>\\\")) {\\n                throw \\\"not xxx\\\";\\n            }\\n            var txts = net.replace(/#EXTINF:-1 ,/g, '')\\n                .replace(/#EXTINF:-1,/g, '')\\n                .replace(/\\\\n#genre#/g, ',#genre#')\\n                .replace(/#EXTINF:-1/g, '')\\n                .replace(/group-title=\\\"/g, '')\\n                .replace(/\\\\nhttp/g, ',http')\\n                //.replace(/=/g, '')\\n                .replace(/Ôºå#/g, ',#')\\n                .replace(/\\\",/g, '/')\\n                .replace(/ /g, '')\\n                .split('\\\\n');\\n            const d1 = []\\n            for (var i = 0; i < txts.length; i++) {\\n                var r = {};\\n                var j = txts[i].split(',');\\n                if (txts[i].indexOf(\\\"#EXTINF\\\") == 0 &&\\n                    j.length == 3 && j[2].indexOf(\\\"http\\\") == 0) {\\n                    r.title = j[1].split('/')[j[0].split('/').length - 1];\\n                    r.url = j[2].replace(`\\\\n`, '').replace('\\\\r', '');\\n                    if (r.url.indexOf(\\\"http\\\") == 0 || r.url.indexOf(\\\"rtmp\\\") == 0 || r.url.indexOf(\\\"rtsp\\\") == 0) {\\n                        r.url = r.url + \\\"#isVideo=true#\\\";\\n                    }\\n                    d1.push(r);\\n                    continue;\\n                }\\n\\n                if (j.length < 2) {\\n                    continue;\\n                }\\n                r.title = j[0].split('/')[j[0].split('/').length - 1];\\n                if (filter != null && !r.title.includes(filter)) {\\n                    continue;\\n                }\\n                r.url = j[1].replace(`\\\\n`, '').replace('\\\\r', '');\\n                if (r.url.indexOf(\\\"http\\\") == 0 || r.url.indexOf(\\\"rtmp\\\") == 0 || r.url.indexOf(\\\"rtsp\\\") == 0) {\\n                    r.url = r.url + \\\"#isVideo=true#\\\";\\n                }\\n                if (r.url.includes(\\\"/at/xml\\\") ||\\n                    r.url.endsWith(\\\"=#isVideo=true#\\\") ||\\n                    r.url.endsWith(\\\"xml#isVideo=true#\\\") ||\\n                    r.url.endsWith(\\\"api.php#isVideo=true#\\\")) {\\n                    continue;\\n                }\\n                d1.push(r);\\n            }\\n            //Â§öÁ∫øË∑Ø\\n            const d2 = {}\\n            for (let it of d1) {\\n                if (d2[it.title] == null) {\\n                    d2[it.title] = []\\n                }\\n                d2[it.title].push(it.url)\\n            }\\n\\n            for (let it of Object.keys(d2)) {\\n                _d.push({\\n                    title: it,\\n                    url: JSON.stringify({\\n                        urls: d2[it]\\n                    })\\n                })\\n            }\\n        } catch (e) {}\\n        if (_d && _d.length) {\\n            data = data.concat(_d)\\n            saveFile(\\\"data.json\\\", JSON.stringify(_d));\\n        } else {\\n            let _td = readFile(\\\"data.json\\\");\\n            if (_td) {\\n                data = data.concat(JSON.parse(_td))\\n            }\\n        }\\n    } catch (e) {\\n        data.push({\\n            title: \\\"Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•\\\",\\n            desc: JSON.stringify(e),\\n            col_type: \\\"text_1\\\"\\n        })\\n    }\\n}\\n$.exports = {\\n    renderLiveData: renderLiveData,\\n}\"}]",
        "icon": ""
    },
    {
        "last_chapter_rule": "",
        "title": "ËΩªÁõ¥Êí≠.ÂΩ±ËßÜÈ¢ëÈÅì",
        "author": "Â∞èÊ£âË¢ÑüåûÂÖ•Êàè",
        "url": "hiker://empty##https://shuyuan.miaogongzi.net/shuyuan/1640533698.txt",
        "version": 32,
        "col_type": "text_3",
        "class_name": "",
        "type": "live",
        "class_url": "",
        "area_name": "",
        "area_url": "",
        "sort_name": "",
        "year_name": "",
        "sort_url": "",
        "year_url": "",
        "find_rule": "js:\nvar data = [];\ndata.push({\n    title: \"üîé\",\n    url: \"'hiker://search?rule=\" + MY_RULE.title + \"&s='+input\",\n    desc: \"ÊêúÁ¥¢È¢ëÈÅì\",\n    col_type: \"input\"\n})\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1])\nsetResult(data);",
        "search_url": "hiker://empty##**",
        "group": "‚ë•Áõ¥Êí≠",
        "searchFind": "js:\nlet rule = JSON.parse(fetch(\"hiker://home@\" + MY_RULE.title))\nlet key = MY_URL.split(\"##\")[1];\nMY_URL = rule.url;\nvar data = [];\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1], key)\nsetResult(data);",
        "detail_col_type": "movie_1",
        "detail_find_rule": "",
        "sdetail_col_type": "movie_1",
        "sdetail_find_rule": "",
        "ua": "mobile",
        "preRule": "",
        "pages": "[{\"col_type\":\"movie_3\",\"name\":\"Â∑•ÂÖ∑\",\"path\":\"tool\",\"rule\":\"function getReferer(url) {\\n    if (url.indexOf(\\\"gitee\\\") > 0) {\\n        return \\\"https://\\\" + url.split(\\\"://\\\")[1].split(\\\"/\\\")[0];\\n    } else {\\n        return null\\n    }\\n}\\n\\nfunction renderLiveData(url, filter) {\\n    try {\\n        let _d = [];\\n        try {\\n            let net = request(url, {\\n                headers: {\\n                    Referer: getReferer(url)\\n                }\\n            });\\n            if (net.includes(\\\"<html>\\\")) {\\n                throw \\\"not xxx\\\";\\n            }\\n            var txts = net.replace(/#EXTINF:-1 ,/g, '')\\n                .replace(/#EXTINF:-1,/g, '')\\n                .replace(/\\\\n#genre#/g, ',#genre#')\\n                .replace(/#EXTINF:-1/g, '')\\n                .replace(/group-title=\\\"/g, '')\\n                .replace(/\\\\nhttp/g, ',http')\\n                .replace(/=/g, '')\\n                .replace(/Ôºå#/g, ',#')\\n                .replace(/\\\",/g, '/')\\n                .replace(/ /g, '')\\n                .split('\\\\n');\\n            const d1 = []\\n            for (var i = 0; i < txts.length; i++) {\\n                var r = {};\\n                var j = txts[i].split(',');\\n                if (txts[i].indexOf(\\\"#EXTINF\\\") == 0 &&\\n                    j.length == 3 && j[2].indexOf(\\\"http\\\") == 0) {\\n                    r.title = j[1].split('/')[j[0].split('/').length - 1];\\n                    r.url = j[2].replace(`\\\\n`, '').replace('\\\\r', '');\\n                    if (r.url.indexOf(\\\"http\\\") == 0) {\\n                        r.url = r.url + \\\"#isVideo=true#\\\";\\n                    }\\n                    d1.push(r);\\n                    continue;\\n                }\\n\\n                if (j.length < 2) {\\n                    continue;\\n                }\\n                r.title = j[0].split('/')[j[0].split('/').length - 1];\\n                if (filter != null && !r.title.includes(filter)) {\\n                    continue;\\n                }\\n                r.url = j[1].replace(`\\\\n`, '').replace('\\\\r', '');\\n                if (r.url.indexOf(\\\"http\\\") == 0) {\\n                    r.url = r.url + \\\"#isVideo=true#\\\";\\n                }\\n                d1.push(r);\\n            }\\n            //Â§öÁ∫øË∑Ø\\n            const d2 = {}\\n            for (let it of d1) {\\n                if (d2[it.title] == null) {\\n                    d2[it.title] = []\\n                }\\n                d2[it.title].push(it.url)\\n            }\\n\\n            for (let it of Object.keys(d2)) {\\n                _d.push({\\n                    title: it,\\n                    url: JSON.stringify({\\n                        urls: d2[it]\\n                    })\\n                })\\n            }\\n        } catch (e) {}\\n        if (_d && _d.length) {\\n            data = data.concat(_d)\\n            saveFile(\\\"data.json\\\", JSON.stringify(_d));\\n        } else {\\n            let _td = readFile(\\\"data.json\\\");\\n            if (_td) {\\n                data = data.concat(JSON.parse(_td))\\n            }\\n        }\\n    } catch (e) {\\n        data.push({\\n            title: \\\"Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•\\\",\\n            desc: JSON.stringify(e),\\n            col_type: \\\"text_1\\\"\\n        })\\n    }\\n}\\n$.exports = {\\n    renderLiveData: renderLiveData,\\n}\"}]",
        "icon": ""
    },
    {
        "last_chapter_rule": "",
        "title": "ËΩªÁõ¥Êí≠.‰πÖ‰πÖ",
        "author": "Â∞èÊ£âË¢ÑüåûÂÖ•Êàè",
        "url": "hiker://empty##https://shuyuan.miaogongzi.net/shuyuan/1640542048.txt",
        "version": 32,
        "col_type": "text_3",
        "class_name": "",
        "type": "live",
        "class_url": "",
        "area_name": "",
        "area_url": "",
        "sort_name": "",
        "year_name": "",
        "sort_url": "",
        "year_url": "",
        "find_rule": "js:\nvar data = [];\ndata.push({\n    title: \"üîé\",\n    url: \"'hiker://search?rule=\" + MY_RULE.title + \"&s='+input\",\n    desc: \"ÊêúÁ¥¢È¢ëÈÅì\",\n    col_type: \"input\"\n})\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1])\nsetResult(data);",
        "search_url": "hiker://empty##**",
        "group": "‚ë•Áõ¥Êí≠",
        "searchFind": "js:\nlet rule = JSON.parse(fetch(\"hiker://home@\" + MY_RULE.title))\nlet key = MY_URL.split(\"##\")[1];\nMY_URL = rule.url;\nvar data = [];\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1], key)\nsetResult(data);",
        "detail_col_type": "movie_1",
        "detail_find_rule": "",
        "sdetail_col_type": "movie_1",
        "sdetail_find_rule": "",
        "ua": "mobile",
        "preRule": "",
        "pages": "[{\"col_type\":\"movie_3\",\"name\":\"Â∑•ÂÖ∑\",\"path\":\"tool\",\"rule\":\"function getReferer(url) {\\n    if (url.indexOf(\\\"gitee\\\") > 0) {\\n        return \\\"https://\\\" + url.split(\\\"://\\\")[1].split(\\\"/\\\")[0];\\n    } else {\\n        return null\\n    }\\n}\\n\\nfunction renderLiveData(url, filter) {\\n    try {\\n        let _d = [];\\n        try {\\n            let net = request(url, {\\n                headers: {\\n                    Referer: getReferer(url)\\n                }\\n            });\\n            if (net.includes(\\\"<html>\\\")) {\\n                throw \\\"not xxx\\\";\\n            }\\n            var txts = net.replace(/#EXTINF:-1 ,/g, '')\\n                .replace(/#EXTINF:-1,/g, '')\\n                .replace(/\\\\n#genre#/g, ',#genre#')\\n                .replace(/#EXTINF:-1/g, '')\\n                .replace(/group-title=\\\"/g, '')\\n                .replace(/\\\\nhttp/g, ',http')\\n                .replace(/=/g, '')\\n                .replace(/Ôºå#/g, ',#')\\n                .replace(/\\\",/g, '/')\\n                .replace(/ /g, '')\\n                .split('\\\\n');\\n            const d1 = []\\n            for (var i = 0; i < txts.length; i++) {\\n                var r = {};\\n                var j = txts[i].split(',');\\n                if (txts[i].indexOf(\\\"#EXTINF\\\") == 0 &&\\n                    j.length == 3 && j[2].indexOf(\\\"http\\\") == 0) {\\n                    r.title = j[1].split('/')[j[0].split('/').length - 1];\\n                    r.url = j[2].replace(`\\\\n`, '').replace('\\\\r', '');\\n                    if (r.url.indexOf(\\\"http\\\") == 0) {\\n                        r.url = r.url + \\\"#isVideo=true#\\\";\\n                    }\\n                    d1.push(r);\\n                    continue;\\n                }\\n\\n                if (j.length < 2) {\\n                    continue;\\n                }\\n                r.title = j[0].split('/')[j[0].split('/').length - 1];\\n                if (filter != null && !r.title.includes(filter)) {\\n                    continue;\\n                }\\n                r.url = j[1].replace(`\\\\n`, '').replace('\\\\r', '');\\n                if (r.url.indexOf(\\\"http\\\") == 0) {\\n                    r.url = r.url + \\\"#isVideo=true#\\\";\\n                }\\n                d1.push(r);\\n            }\\n            //Â§öÁ∫øË∑Ø\\n            const d2 = {}\\n            for (let it of d1) {\\n                if (d2[it.title] == null) {\\n                    d2[it.title] = []\\n                }\\n                d2[it.title].push(it.url)\\n            }\\n\\n            for (let it of Object.keys(d2)) {\\n                _d.push({\\n                    title: it,\\n                    url: JSON.stringify({\\n                        urls: d2[it]\\n                    })\\n                })\\n            }\\n        } catch (e) {}\\n        if (_d && _d.length) {\\n            data = data.concat(_d)\\n            saveFile(\\\"data.json\\\", JSON.stringify(_d));\\n        } else {\\n            let _td = readFile(\\\"data.json\\\");\\n            if (_td) {\\n                data = data.concat(JSON.parse(_td))\\n            }\\n        }\\n    } catch (e) {\\n        data.push({\\n            title: \\\"Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•\\\",\\n            desc: JSON.stringify(e),\\n            col_type: \\\"text_1\\\"\\n        })\\n    }\\n}\\n$.exports = {\\n    renderLiveData: renderLiveData,\\n}\"}]",
        "icon": ""
    },
    {
        "last_chapter_rule": "",
        "title": "ËΩªÁõ¥Êí≠.TeeÊµãËØï",
        "author": "Â∞èÊ£âË¢Ñüåû",
        "url": "hiker://empty##https://shuyuan.miaogongzi.net/shuyuan/1640882974.txt",
        "version": 20211230,
        "col_type": "text_3",
        "class_name": "",
        "type": "live",
        "class_url": "",
        "area_name": "",
        "area_url": "",
        "sort_name": "",
        "year_name": "",
        "sort_url": "",
        "year_url": "",
        "find_rule": "js:\nvar data = [];\ndata.push({\n    title: \"üîé\",\n    url: \"'hiker://search?rule=\" + MY_RULE.title + \"&s='+input\",\n    desc: \"ÊêúÁ¥¢È¢ëÈÅì\",\n    col_type: \"input\"\n})\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1])\nsetResult(data);",
        "search_url": "hiker://empty##**",
        "group": "‚ë•Áõ¥Êí≠",
        "searchFind": "js:\nlet rule = JSON.parse(fetch(\"hiker://home@\" + MY_RULE.title))\nlet key = MY_URL.split(\"##\")[1];\nMY_URL = rule.url;\nvar data = [];\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1], key)\nsetResult(data);",
        "detail_col_type": "movie_1",
        "detail_find_rule": "",
        "sdetail_col_type": "movie_1",
        "sdetail_find_rule": "",
        "ua": "mobile",
        "preRule": "",
        "pages": "[{\"col_type\":\"movie_3\",\"name\":\"Â∑•ÂÖ∑\",\"path\":\"tool\",\"rule\":\"function getReferer(url) {\\n    if (url.indexOf(\\\"gitee\\\") > 0) {\\n        return \\\"https://\\\" + url.split(\\\"://\\\")[1].split(\\\"/\\\")[0];\\n    } else {\\n        return null\\n    }\\n}\\n\\nfunction renderLiveData(url, filter) {\\n    try {\\n        let _d = [];\\n        try {\\n            let net = request(url, {\\n                headers: {\\n                    Referer: getReferer(url)\\n                }\\n            });\\n            if (net.includes(\\\"<html>\\\")) {\\n                throw \\\"not xxx\\\";\\n            }\\n            var txts = net.replace(/#EXTINF:-1 ,/g, '')\\n                .replace(/#EXTINF:-1,/g, '')\\n                .replace(/\\\\n#genre#/g, ',#genre#')\\n                .replace(/#EXTINF:-1/g, '')\\n                .replace(/group-title=\\\"/g, '')\\n                .replace(/\\\\nhttp/g, ',http')\\n                .replace(/=/g, '')\\n                .replace(/Ôºå#/g, ',#')\\n                .replace(/\\\",/g, '/')\\n                .replace(/ /g, '')\\n                .split('\\\\n');\\n            const d1 = []\\n            for (var i = 0; i < txts.length; i++) {\\n                var r = {};\\n                var j = txts[i].split(',');\\n                if (txts[i].indexOf(\\\"#EXTINF\\\") == 0 &&\\n                    j.length == 3 && j[2].indexOf(\\\"http\\\") == 0) {\\n                    r.title = j[1].split('/')[j[0].split('/').length - 1];\\n                    r.url = j[2].replace(`\\\\n`, '').replace('\\\\r', '');\\n                    if (r.url.indexOf(\\\"http\\\") == 0) {\\n                        r.url = r.url + \\\"#isVideo=true#\\\";\\n                    }\\n                    d1.push(r);\\n                    continue;\\n                }\\n\\n                if (j.length < 2) {\\n                    continue;\\n                }\\n                r.title = j[0].split('/')[j[0].split('/').length - 1];\\n                if (filter != null && !r.title.includes(filter)) {\\n                    continue;\\n                }\\n                r.url = j[1].replace(`\\\\n`, '').replace('\\\\r', '');\\n                if (r.url.indexOf(\\\"http\\\") == 0) {\\n                    r.url = r.url + \\\"#isVideo=true#\\\";\\n                }\\n                d1.push(r);\\n            }\\n            //Â§öÁ∫øË∑Ø\\n            const d2 = {}\\n            for (let it of d1) {\\n                if (d2[it.title] == null) {\\n                    d2[it.title] = []\\n                }\\n                d2[it.title].push(it.url)\\n            }\\n\\n            for (let it of Object.keys(d2)) {\\n                _d.push({\\n                    title: it,\\n                    url: JSON.stringify({\\n                        urls: d2[it]\\n                    })\\n                })\\n            }\\n        } catch (e) {}\\n        if (_d && _d.length) {\\n            data = data.concat(_d)\\n            saveFile(\\\"data.json\\\", JSON.stringify(_d));\\n        } else {\\n            let _td = readFile(\\\"data.json\\\");\\n            if (_td) {\\n                data = data.concat(JSON.parse(_td))\\n            }\\n        }\\n    } catch (e) {\\n        data.push({\\n            title: \\\"Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•\\\",\\n            desc: JSON.stringify(e),\\n            col_type: \\\"text_1\\\"\\n        })\\n    }\\n}\\n$.exports = {\\n    renderLiveData: renderLiveData,\\n}\"}]",
        "icon": ""
    },
    {
        "last_chapter_rule": "",
        "title": "ËΩªÁõ¥Êí≠.Êô¥Âõ≠",
        "author": "Â∞èÊ£âË¢Ñüåû",
        "url": "hiker://empty##https://ml.giteecn.workers.dev/itvlist/channel/main/list/qyzb.m3u",
        "version": 20211230,
        "col_type": "text_3",
        "class_name": "",
        "type": "live",
        "class_url": "",
        "area_name": "",
        "area_url": "",
        "sort_name": "",
        "year_name": "",
        "sort_url": "",
        "year_url": "",
        "find_rule": "js:\nvar data = [];\ndata.push({\n    title: \"üîé\",\n    url: \"'hiker://search?rule=\" + MY_RULE.title + \"&s='+input\",\n    desc: \"ÊêúÁ¥¢È¢ëÈÅì\",\n    col_type: \"input\"\n})\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1])\nsetResult(data);",
        "search_url": "hiker://empty##**",
        "group": "‚ë•Áõ¥Êí≠",
        "searchFind": "js:\nlet rule = JSON.parse(fetch(\"hiker://home@\" + MY_RULE.title))\nlet key = MY_URL.split(\"##\")[1];\nMY_URL = rule.url;\nvar data = [];\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1], key)\nsetResult(data);",
        "detail_col_type": "movie_1",
        "detail_find_rule": "",
        "sdetail_col_type": "movie_1",
        "sdetail_find_rule": "",
        "ua": "mobile",
        "preRule": "",
        "pages": "[{\"col_type\":\"movie_3\",\"name\":\"Â∑•ÂÖ∑\",\"path\":\"tool\",\"rule\":\"function getReferer(url) {\\n    if (url.indexOf(\\\"gitee\\\") > 0) {\\n        return \\\"https://\\\" + url.split(\\\"://\\\")[1].split(\\\"/\\\")[0];\\n    } else {\\n        return null\\n    }\\n}\\n\\nfunction renderLiveData(url, filter) {\\n    try {\\n        let _d = [];\\n        try {\\n            let net = request(url, {\\n                headers: {\\n                    Referer: getReferer(url)\\n                }\\n            });\\n            if (net.includes(\\\"<html>\\\")) {\\n                throw \\\"not xxx\\\";\\n            }\\n            var txts = net.replace(/#EXTINF:-1 ,/g, '')\\n                .replace(/#EXTINF:-1,/g, '')\\n                .replace(/\\\\n#genre#/g, ',#genre#')\\n                .replace(/#EXTINF:-1/g, '')\\n                .replace(/group-title=\\\"/g, '')\\n                .replace(/\\\\nhttp/g, ',http')\\n                .replace(/=/g, '')\\n                .replace(/Ôºå#/g, ',#')\\n                .replace(/\\\",/g, '/')\\n                .replace(/ /g, '')\\n                .split('\\\\n');\\n            const d1 = []\\n            for (var i = 0; i < txts.length; i++) {\\n                var r = {};\\n                var j = txts[i].split(',');\\n                if (txts[i].indexOf(\\\"#EXTINF\\\") == 0 &&\\n                    j.length == 3 && j[2].indexOf(\\\"http\\\") == 0) {\\n                    r.title = j[1].split('/')[j[0].split('/').length - 1];\\n                    r.url = j[2].replace(`\\\\n`, '').replace('\\\\r', '');\\n                    if (r.url.indexOf(\\\"http\\\") == 0) {\\n                        r.url = r.url + \\\"#isVideo=true#\\\";\\n                    }\\n                    d1.push(r);\\n                    continue;\\n                }\\n\\n                if (j.length < 2) {\\n                    continue;\\n                }\\n                r.title = j[0].split('/')[j[0].split('/').length - 1];\\n                if (filter != null && !r.title.includes(filter)) {\\n                    continue;\\n                }\\n                r.url = j[1].replace(`\\\\n`, '').replace('\\\\r', '');\\n                if (r.url.indexOf(\\\"http\\\") == 0) {\\n                    r.url = r.url + \\\"#isVideo=true#\\\";\\n                }\\n                d1.push(r);\\n            }\\n            //Â§öÁ∫øË∑Ø\\n            const d2 = {}\\n            for (let it of d1) {\\n                if (d2[it.title] == null) {\\n                    d2[it.title] = []\\n                }\\n                d2[it.title].push(it.url)\\n            }\\n\\n            for (let it of Object.keys(d2)) {\\n                _d.push({\\n                    title: it,\\n                    url: JSON.stringify({\\n                        urls: d2[it]\\n                    })\\n                })\\n            }\\n        } catch (e) {}\\n        if (_d && _d.length) {\\n            data = data.concat(_d)\\n            saveFile(\\\"data.json\\\", JSON.stringify(_d));\\n        } else {\\n            let _td = readFile(\\\"data.json\\\");\\n            if (_td) {\\n                data = data.concat(JSON.parse(_td))\\n            }\\n        }\\n    } catch (e) {\\n        data.push({\\n            title: \\\"Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•\\\",\\n            desc: JSON.stringify(e),\\n            col_type: \\\"text_1\\\"\\n        })\\n    }\\n}\\n$.exports = {\\n    renderLiveData: renderLiveData,\\n}\"}]",
        "icon": ""
    },
    {
        "last_chapter_rule": "",
        "title": "ÂÖÉÊó¶Áõ¥Êí≠",
        "author": "ÂÖ•Êàè",
        "url": "hiker://empty##https://shuyuan.miaogongzi.net/shuyuan/1641197698.txt",
        "version": 32,
        "col_type": "text_3",
        "class_name": "",
        "type": "live",
        "class_url": "",
        "area_name": "",
        "area_url": "",
        "sort_name": "",
        "year_name": "",
        "sort_url": "",
        "year_url": "",
        "find_rule": "js:\nvar data = [];\ndata.push({\n    title: \"üîé\",\n    url: \"'hiker://search?rule=\" + MY_RULE.title + \"&s='+input\",\n    desc: \"ÊêúÁ¥¢È¢ëÈÅì\",\n    col_type: \"input\"\n})\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1])\nsetResult(data);",
        "search_url": "hiker://empty##**",
        "group": "‚ë•Áõ¥Êí≠",
        "searchFind": "js:\nlet rule = JSON.parse(fetch(\"hiker://home@\" + MY_RULE.title))\nlet key = MY_URL.split(\"##\")[1];\nMY_URL = rule.url;\nvar data = [];\nconst {\n    renderLiveData\n} = $.require(\"hiker://page/tool\")\nrenderLiveData(MY_URL.split(\"##\")[1], key)\nsetResult(data);",
        "detail_col_type": "movie_1",
        "detail_find_rule": "",
        "sdetail_col_type": "movie_1",
        "sdetail_find_rule": "",
        "ua": "mobile",
        "preRule": "",
        "pages": "[{\"col_type\":\"movie_3\",\"name\":\"Â∑•ÂÖ∑\",\"path\":\"tool\",\"rule\":\"function getReferer(url) {\\n    if (url.indexOf(\\\"gitee\\\") > 0) {\\n        return \\\"https://\\\" + url.split(\\\"://\\\")[1].split(\\\"/\\\")[0];\\n    } else {\\n        return null\\n    }\\n}\\n\\nfunction renderLiveData(url, filter) {\\n    try {\\n        let _d = [];\\n        try {\\n            let net = request(url, {\\n                headers: {\\n                    Referer: getReferer(url)\\n                }\\n            });\\n            if (net.includes(\\\"<html>\\\")) {\\n                throw \\\"not xxx\\\";\\n            }\\n            var txts = net.replace(/#EXTINF:-1 ,/g, '')\\n                .replace(/#EXTINF:-1,/g, '')\\n                .replace(/\\\\n#genre#/g, ',#genre#')\\n                .replace(/#EXTINF:-1/g, '')\\n                .replace(/group-title=\\\"/g, '')\\n                .replace(/\\\\nhttp/g, ',http')\\n                .replace(/=/g, '')\\n                .replace(/Ôºå#/g, ',#')\\n                .replace(/\\\",/g, '/')\\n                .replace(/ /g, '')\\n                .split('\\\\n');\\n            const d1 = []\\n            for (var i = 0; i < txts.length; i++) {\\n                var r = {};\\n                var j = txts[i].split(',');\\n                if (txts[i].indexOf(\\\"#EXTINF\\\") == 0 &&\\n                    j.length == 3 && j[2].indexOf(\\\"http\\\") == 0) {\\n                    r.title = j[1].split('/')[j[0].split('/').length - 1];\\n                    r.url = j[2].replace(`\\\\n`, '').replace('\\\\r', '');\\n                    if (r.url.indexOf(\\\"http\\\") == 0) {\\n                        r.url = r.url + \\\"#isVideo=true#\\\";\\n                    }\\n                    d1.push(r);\\n                    continue;\\n                }\\n\\n                if (j.length < 2) {\\n                    continue;\\n                }\\n                r.title = j[0].split('/')[j[0].split('/').length - 1];\\n                if (filter != null && !r.title.includes(filter)) {\\n                    continue;\\n                }\\n                r.url = j[1].replace(`\\\\n`, '').replace('\\\\r', '');\\n                if (r.url.indexOf(\\\"http\\\") == 0) {\\n                    r.url = r.url + \\\"#isVideo=true#\\\";\\n                }\\n                d1.push(r);\\n            }\\n            //Â§öÁ∫øË∑Ø\\n            const d2 = {}\\n            for (let it of d1) {\\n                if (d2[it.title] == null) {\\n                    d2[it.title] = []\\n                }\\n                d2[it.title].push(it.url)\\n            }\\n\\n            for (let it of Object.keys(d2)) {\\n                _d.push({\\n                    title: it,\\n                    url: JSON.stringify({\\n                        urls: d2[it]\\n                    })\\n                })\\n            }\\n        } catch (e) {}\\n        if (_d && _d.length) {\\n            data = data.concat(_d)\\n            saveFile(\\\"data.json\\\", JSON.stringify(_d));\\n        } else {\\n            let _td = readFile(\\\"data.json\\\");\\n            if (_td) {\\n                data = data.concat(JSON.parse(_td))\\n            }\\n        }\\n    } catch (e) {\\n        data.push({\\n            title: \\\"Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•\\\",\\n            desc: JSON.stringify(e),\\n            col_type: \\\"text_1\\\"\\n        })\\n    }\\n}\\n$.exports = {\\n    renderLiveData: renderLiveData,\\n}\"}]",
        "icon": ""
    }
]